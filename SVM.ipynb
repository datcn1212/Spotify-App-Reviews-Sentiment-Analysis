{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d18a89",
   "metadata": {},
   "source": [
    "## Spotify App Reviews Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c17717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b75b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stf = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d6e51b",
   "metadata": {},
   "source": [
    "### Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e68a6286",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/canada/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: gensim in /home/canada/.local/lib/python3.10/site-packages (4.3.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/canada/.local/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /home/canada/.local/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /home/canada/.local/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/canada/.local/lib/python3.10/site-packages (from gensim) (1.23.4)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in /home/canada/.local/lib/python3.10/site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/canada/.local/lib/python3.10/site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/canada/.local/lib/python3.10/site-packages (from gensim) (1.10.0)\n",
      "Requirement already satisfied: pyfume in /home/canada/.local/lib/python3.10/site-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
      "Requirement already satisfied: pandas in /home/canada/.local/lib/python3.10/site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/canada/.local/lib/python3.10/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.1)\n",
      "Requirement already satisfied: fst-pso in /home/canada/.local/lib/python3.10/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: simpful in /home/canada/.local/lib/python3.10/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: miniful in /home/canada/.local/lib/python3.10/site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
      "Requirement already satisfied: requests in /home/canada/.local/lib/python3.10/site-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/canada/.local/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12eaa80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    great music service audio high quality app eas...\n",
       "1    please ignore previous negative rating app sup...\n",
       "2    pop get best spotify experience android annoyi...\n",
       "3                   really buggy terrible use recently\n",
       "4     dear spotify get songs put playlist shuffle play\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stf['Review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da55e5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/canada/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum, strip_multiple_whitespaces, preprocess_string, split_alphanum, strip_short, strip_numeric\n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45914ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(docs):\n",
    "  return [doc.lower() for doc in docs]\n",
    "\n",
    "def remove_punc(docs):\n",
    "  return [strip_non_alphanum(doc).strip() for doc in docs]\n",
    "\n",
    "def separate_num(docs):\n",
    "  return [split_alphanum(doc) for doc in docs]\n",
    "\n",
    "def remove_one_letter_word(docs):\n",
    "  return [strip_short(doc) for doc in docs]\n",
    "\n",
    "def remove_number(docs):\n",
    "  return [strip_numeric(doc) for doc in docs]\n",
    "\n",
    "def replace_multiple_whitespaces(docs):\n",
    "  return [strip_multiple_whitespaces(doc) for doc in docs]\n",
    "\n",
    "def remove_stopwords(docs):\n",
    "    return [\" \".join([word for word in doc.split() if word not in stop_words]) for doc in docs]\n",
    "\n",
    "doc = lower_case(stf['Review'])\n",
    "doc = remove_punc(doc)\n",
    "doc = separate_num(doc)\n",
    "doc = remove_one_letter_word(doc)\n",
    "doc = remove_number(doc)\n",
    "doc = replace_multiple_whitespaces(doc)\n",
    "doc = remove_stopwords(doc)\n",
    "\n",
    "stf['Review'] = doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06270d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    great music service audio high quality app eas...\n",
       "1    please ignore previous negative rating app sup...\n",
       "2    pop get best spotify experience android annoyi...\n",
       "3                   really buggy terrible use recently\n",
       "4     dear spotify get songs put playlist shuffle play\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stf['Review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0b87123",
   "metadata": {},
   "outputs": [],
   "source": [
    "stf1 = stf.copy()\n",
    "rate = [1,2,3,4,5]\n",
    "sentiment = [0, 0, 1, 1, 1]\n",
    "for i in range(5):\n",
    "    stf1[\"Rating\"].replace(rate[i], sentiment[i],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09d34668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61594 entries, 0 to 61593\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Time_submitted  61594 non-null  object\n",
      " 1   Review          61594 non-null  object\n",
      " 2   Rating          61594 non-null  int64 \n",
      " 3   Total_thumbsup  61594 non-null  int64 \n",
      " 4   Reply           216 non-null    object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "stf1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e6129",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3c0b5dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]................................*..................*.*\n",
      "optimization finished, #iter = 51535\n",
      "obj = -17712.833044, rho = 0.451040\n",
      "nSV = 21613, nBSV = 17734\n",
      "Total nSV = 21613\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [83], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m X_test_vectors \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m     14\u001b[0m svm \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43msvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m train_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_train, svm\u001b[38;5;241m.\u001b[39mpredict(X_train_vectors))\n\u001b[1;32m     18\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:252\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    251\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m--> 252\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:373\u001b[0m, in \u001b[0;36mBaseLibSVM._sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    359\u001b[0m kernel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_kernels\u001b[38;5;241m.\u001b[39mindex(kernel)\n\u001b[1;32m    361\u001b[0m libsvm_sparse\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m    363\u001b[0m (\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[1;32m    366\u001b[0m     dual_coef_data,\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[0;32m--> 373\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm_sparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibsvm_sparse_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32msklearn/svm/_libsvm_sparse.pyx:191\u001b[0m, in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_compressed.py:26\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_cs_matrix\u001b[39;00m(_data_matrix, _minmax_mixin, IndexMixin):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124;03m\"\"\"base matrix class for compressed row- and column-oriented matrices\"\"\"\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg1, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     27\u001b[0m         _data_matrix\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m isspmatrix(arg1):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(stf1['Review'], stf1['Rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "# TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_test_vectors = vectorizer.transform(X_test)\n",
    "\n",
    "svm = SVC(kernel='linear', verbose=True)\n",
    "svm.fit(X_train_vectors, y_train)\n",
    "\n",
    "train_accuracy_0 = accuracy_score(y_train, svm.predict(X_train_vectors))\n",
    "test_accuracy_0 = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Train accuracy:\", train_accuracy_0)\n",
    "print(\"Test accuracy:\", test_accuracy_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eee50f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_vectors)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a68ccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['negative']\n"
     ]
    }
   ],
   "source": [
    "new_data = [\"terrible\"]\n",
    "\n",
    "new_data_vectors = vectorizer.transform(new_data)\n",
    "\n",
    "new_predictions = svm.predict(new_data_vectors)\n",
    "\n",
    "print(\"Predictions:\", new_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6becabe2",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f6097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(stf1['Review'], stf1['Rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_test_vectors = vectorizer.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(X_train_vectors, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_vectors)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, clf.predict(X_train_vectors))\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Train accuracy:\", train_accuracy)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c4ec1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8573592179540135\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_vectors)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c3ed138a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: Positve\n"
     ]
    }
   ],
   "source": [
    "new_data = [\"I feel this app is an exciting app\"]\n",
    "\n",
    "new_data_vectors = vectorizer.transform(new_data)\n",
    "\n",
    "new_predictions = 'Positve' if (clf.predict(new_data_vectors) == 1) else 'Negative'\n",
    "\n",
    "print(\"Predictions:\", new_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc94f99b",
   "metadata": {},
   "source": [
    "### Random Forest & Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "959116a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d13c9646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9986605783866058\n",
      "Test accuracy: 0.8155694455718808\n",
      "F1 score: 0.8415841584158416\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_vectors, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test_vectors)\n",
    "\n",
    "train_accuracy_1 = accuracy_score(y_train, rf.predict(X_train_vectors))\n",
    "test_accuracy_1 = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "print(\"Train accuracy:\", train_accuracy_1)\n",
    "print(\"Test accuracy:\", test_accuracy_1)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0da528bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8343581938102486\n",
      "Test accuracy: 0.8098871661660849\n",
      "F1 score: 0.8418422474338195\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_vectors, y_train)\n",
    "\n",
    "y_pred = mnb.predict(X_test_vectors)\n",
    "\n",
    "train_accuracy_2 = accuracy_score(y_train, mnb.predict(X_train_vectors))\n",
    "test_accuracy_2 = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "print(\"Train accuracy:\", train_accuracy_2)\n",
    "print(\"Test accuracy:\", test_accuracy_2)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {'Model':['RandomForestClassifier-train','RandomForestClassifier-test', \n",
    "                  'MultinomialNBClassifier-train', 'MultinomialNBClassifier-test',\n",
    "                  'LogisticRegression-train','LogisticRegression-test',\n",
    "                  'SVM-train','SVM-test'],\n",
    "         'Accuracy':[train_accuracy_1,test_accuracy_1,train_accuracy_2,test_accuracy_2, \n",
    "                     train_accuracy,test_accuracy,\n",
    "                     train_accuracy_0,test_accuracy_0]\n",
    "         }\n",
    "model_df = pd.DataFrame(model)\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95108b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
