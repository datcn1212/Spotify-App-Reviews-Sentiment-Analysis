{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d18a89",
   "metadata": {},
   "source": [
    "## Spotify App Reviews Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c17717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b75b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stf = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d6e51b",
   "metadata": {},
   "source": [
    "### Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68a6286",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m160.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 KB\u001b[0m \u001b[31m75.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting regex>=2021.8.3\n",
      "  Downloading regex-2022.10.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.5/770.5 KB\u001b[0m \u001b[31m160.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m84.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, regex, joblib, nltk\n",
      "Successfully installed joblib-1.2.0 nltk-3.8.1 regex-2022.10.31 tqdm-4.64.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da55e5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/canada/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum, strip_multiple_whitespaces, preprocess_string, split_alphanum, strip_short, strip_numeric\n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45914ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(docs):\n",
    "  return [doc.lower() for doc in docs]\n",
    "\n",
    "# Loai bo dau cau & ki tu dac biet\n",
    "def remove_punc(docs):\n",
    "  return [strip_non_alphanum(doc).strip() for doc in docs]\n",
    "\n",
    "# Tach cac so va chu lien nhau\n",
    "def separate_num(docs):\n",
    "  return [split_alphanum(doc) for doc in docs]\n",
    "\n",
    "def remove_one_letter_word(docs):\n",
    "  return [strip_short(doc) for doc in docs]\n",
    "\n",
    "def remove_number(docs):\n",
    "  return [strip_numeric(doc) for doc in docs]\n",
    "\n",
    "# Thay the nhieu spaces bang mot space\n",
    "def replace_multiple_whitespaces(docs):\n",
    "  return [strip_multiple_whitespaces(doc) for doc in docs]\n",
    "\n",
    "def remove_stopwords(docs):\n",
    "    return [\" \".join([word for word in doc.split() if word not in stop_words]) for doc in docs]\n",
    "\n",
    "doc = lower_case(stf['Review'])\n",
    "doc = remove_punc(doc)\n",
    "doc = separate_num(doc)\n",
    "doc = remove_one_letter_word(doc)\n",
    "doc = remove_number(doc)\n",
    "doc = replace_multiple_whitespaces(doc)\n",
    "doc = remove_stopwords(doc)\n",
    "\n",
    "stf['Review'] = doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06270d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_submitted</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Total_thumbsup</th>\n",
       "      <th>Reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-09 15:00:00</td>\n",
       "      <td>great music service audio high quality app eas...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-09 14:21:22</td>\n",
       "      <td>please ignore previous negative rating app sup...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-09 13:27:32</td>\n",
       "      <td>pop get best spotify experience android annoyi...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-09 13:26:45</td>\n",
       "      <td>really buggy terrible use recently</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-09 13:20:49</td>\n",
       "      <td>dear spotify get songs put playlist shuffle play</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time_submitted                                             Review  \\\n",
       "0  2022-07-09 15:00:00  great music service audio high quality app eas...   \n",
       "1  2022-07-09 14:21:22  please ignore previous negative rating app sup...   \n",
       "2  2022-07-09 13:27:32  pop get best spotify experience android annoyi...   \n",
       "3  2022-07-09 13:26:45                 really buggy terrible use recently   \n",
       "4  2022-07-09 13:20:49   dear spotify get songs put playlist shuffle play   \n",
       "\n",
       "   Rating  Total_thumbsup Reply  \n",
       "0       5               2   NaN  \n",
       "1       5               1   NaN  \n",
       "2       4               0   NaN  \n",
       "3       1               1   NaN  \n",
       "4       1               1   NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0b87123",
   "metadata": {},
   "outputs": [],
   "source": [
    "stf1 = stf.copy()\n",
    "rate = [1,2,3,4,5]\n",
    "sentiment = [0, 0, 1, 1, 1]\n",
    "for i in range(5):\n",
    "    stf1[\"Rating\"].replace(rate[i], sentiment[i],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09d34668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61594 entries, 0 to 61593\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Time_submitted  61594 non-null  object\n",
      " 1   Review          61594 non-null  object\n",
      " 2   Rating          61594 non-null  int64 \n",
      " 3   Total_thumbsup  61594 non-null  int64 \n",
      " 4   Reply           216 non-null    object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "stf1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e6129",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c0b5dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]................................*..................*.*\n",
      "optimization finished, #iter = 51535\n",
      "obj = -17712.833044, rho = 0.451040\n",
      "nSV = 21613, nBSV = 17734\n",
      "Total nSV = 21613\n",
      "Accuracy: 0.8262846010228103\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "# df = pd.read_csv(\"review.csv\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(stf1['Review'], stf1['Rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Transform the text data into numerical features using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_test_vectors = vectorizer.transform(X_test)\n",
    "\n",
    "# Train an SVM classifier on the training data\n",
    "clf = SVC(kernel='linear', verbose=True)\n",
    "clf.fit(X_train_vectors, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test_vectors)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a68ccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['negative']\n"
     ]
    }
   ],
   "source": [
    "# Load new data\n",
    "new_data = [\"terrible\"]\n",
    "\n",
    "# Transform the new data into numerical features using the same TfidfVectorizer\n",
    "new_data_vectors = vectorizer.transform(new_data)\n",
    "\n",
    "# Make predictions on the new data\n",
    "new_predictions = clf.predict(new_data_vectors)\n",
    "\n",
    "# Display the predictions\n",
    "print(\"Predictions:\", new_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7eee50f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'negative'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test_vectors)\n\u001b[0;32m---> 10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Calculate F1 score\u001b[39;00m\n\u001b[1;32m     13\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:134\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m\"\"\"Transform labels to normalized encoding.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Labels as normalized encodings.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 134\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# transform of empty array is empty array\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1179\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;124;03m\"\"\"Ravel column or 1d numpy array, else raises an error.\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;124;03m    If `y` is not a 1D array or a 2D array with a single row or column.\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y)\n\u001b[0;32m-> 1179\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m shape \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:877\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    870\u001b[0m         _assert_all_finite(\n\u001b[1;32m    871\u001b[0m             array,\n\u001b[1;32m    872\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    875\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    876\u001b[0m         )\n\u001b[0;32m--> 877\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    879\u001b[0m     array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_array_api.py:68\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.astype\u001b[0;34m(self, x, dtype, copy, casting)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, dtype, \u001b[38;5;241m*\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# astype is not defined in the top level NumPy namespace\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'negative'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test_vectors)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6becabe2",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c07f6097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8558295281582953\n",
      "Test accuracy: 0.8318045295884406\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(stf1['Review'], stf1['Rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Transform the text data into numerical features using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_test_vectors = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Logistic Regression classifier on the training data\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(X_train_vectors, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test_vectors)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "train_accuracy = accuracy_score(y_train, clf.predict(X_train_vectors))\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Train accuracy:\", train_accuracy)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3ed138a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['positive']\n"
     ]
    }
   ],
   "source": [
    "# Load new data\n",
    "new_data = [\"not\"]\n",
    "\n",
    "# Transform the new data into numerical features using the same TfidfVectorizer\n",
    "new_data_vectors = vectorizer.transform(new_data)\n",
    "\n",
    "# Make predictions on the new data\n",
    "new_predictions = clf.predict(new_data_vectors)\n",
    "\n",
    "# Display the predictions\n",
    "print(\"Predictions:\", new_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0f282c",
   "metadata": {},
   "source": [
    "### Random Forest & Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37c8370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1681d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(stf1['Review'], stf1['Rating'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df81772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(X_train)\n",
    "X_train_tfidf = tfidf.transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "927c6480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier on TF-IDF Vectors: 0.8128094812890657\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier()\n",
    "rf2.fit(X_train_tfidf, y_train)\n",
    "rf_tfidf = rf2.score(X_test_tfidf, y_test)\n",
    "print(f'Random Forest Classifier on TF-IDF Vectors: {rf_tfidf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9e20896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Classifier on TF-IDF Vectors: 0.8098871661660849\n"
     ]
    }
   ],
   "source": [
    "mnb2 = MultinomialNB()\n",
    "mnb2.fit(X_train_tfidf, y_train)\n",
    "mnb_tfidf = mnb2.score(X_test_tfidf, y_test)\n",
    "print(f'Multinomial Naive Bayes Classifier on TF-IDF Vectors: {mnb_tfidf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d8a2ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier-TFIDFVectors</td>\n",
       "      <td>0.812809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNBClassifier-TFIDFVectors</td>\n",
       "      <td>0.809887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model     Score\n",
       "0   RandomForestClassifier-TFIDFVectors  0.812809\n",
       "1  MultinomialNBClassifier-TFIDFVectors  0.809887"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = {'Model':['RandomForestClassifier-TFIDFVectors', \n",
    "                  'MultinomialNBClassifier-TFIDFVectors'],\n",
    "         'Score':[rf_tfidf,mnb_tfidf]\n",
    "         }\n",
    "model_df = pd.DataFrame(model)\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ca57fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
